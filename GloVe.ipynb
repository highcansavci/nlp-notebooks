{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55020466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from future.utils import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a54bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "def cosine_distance(a, b):\n",
    "    return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3837e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, metric = cosine_distance, \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e415cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3):\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(f\"{w} not in dictionary.\")\n",
    "            return\n",
    "    \n",
    "    king = word2vec[w1]\n",
    "    man = word2vec[w2]\n",
    "    woman = word2vec[w3]\n",
    "    v0 = king - man + woman\n",
    "    \n",
    "    min_dist = float('inf')\n",
    "    best_word = ''\n",
    "    for word, v1 in iteritems(word2vec):\n",
    "        if word not in (w1, w2, w3):\n",
    "            d = dist(v0, v1)\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                best_word = word\n",
    "    print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6d4c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies_faster(w1, w2, w3):\n",
    "    for w in (w1, w2, w3):\n",
    "        if w not in word2vec:\n",
    "            print(f\"{w} not in dictionary.\")\n",
    "            return\n",
    "    \n",
    "    king = word2vec[w1]\n",
    "    man = word2vec[w2]\n",
    "    woman = word2vec[w3]\n",
    "    v0 = king - man + woman\n",
    "    \n",
    "    distances = pairwise_distances(v0.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "    idx = distances.argmin()\n",
    "    best_word = idx2word[idx]\n",
    "    print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab35f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(word, n=5):\n",
    "    if word not in word2vec:\n",
    "        print(f\"{word} not in dictionary.\")\n",
    "        return \n",
    "    v = word2vec[word]\n",
    "    distances = pairwise_distances(v.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "    idxs = distances.argsort()[1:n+1]\n",
    "    print(f\"neighbors of {word}:\")\n",
    "    for idx in idxs:\n",
    "        print(f\"\\t{idx2word[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbb3565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "king - man = queen - woman\n",
      "france - paris = britain - london\n",
      "france - paris = italy - rome\n",
      "paris - france = rome - italy\n",
      "france - french = england - english\n",
      "japan - japanese = china - chinese\n",
      "neighbors of woman:\n",
      "\tgirl\n",
      "\tman\n",
      "\tmother\n",
      "\ther\n",
      "\tboy\n",
      "neighbors of nephew:\n",
      "\tcousin\n",
      "\tbrother\n",
      "\tgrandson\n",
      "\tson\n",
      "\tuncle\n",
      "neighbors of february:\n",
      "\toctober\n",
      "\tdecember\n",
      "\tjanuary\n",
      "\taugust\n",
      "\tseptember\n",
      "neighbors of rome:\n",
      "\tnaples\n",
      "\tvenice\n",
      "\titaly\n",
      "\tturin\n",
      "\tpope\n",
      "neighbors of king:\n",
      "\tprince\n",
      "\tqueen\n",
      "\tii\n",
      "\temperor\n",
      "\tson\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading word vectors...\")\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "with open(\"glove.6B.50d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "print(f\"Found {len(word2vec)} word vectors.\")\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape\n",
    "\n",
    "find_analogies(\"king\", \"man\", \"woman\")\n",
    "find_analogies(\"france\", \"paris\", \"london\")\n",
    "find_analogies(\"france\", \"paris\", \"rome\")\n",
    "find_analogies(\"paris\", \"france\", \"italy\")\n",
    "find_analogies(\"france\", \"french\", \"english\")\n",
    "find_analogies(\"japan\", \"japanese\", \"chinese\")\n",
    "\n",
    "nearest_neighbors(\"woman\")\n",
    "nearest_neighbors(\"nephew\")\n",
    "nearest_neighbors(\"february\")\n",
    "nearest_neighbors(\"rome\")\n",
    "nearest_neighbors(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
