{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba029bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3a869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\developer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\developer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\developer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b5a1a",
   "metadata": {},
   "source": [
    "# Text Summarization Using Naive Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34a62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bbc_text_cls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95383a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5e572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[df.labels==\"tech\"][\"text\"].sample(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21716f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30b1993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 'to overtake US net use'\n",
      "\n",
      "The Chinese net-using population looks\n",
      "set to exceed that of the US in less than three years, says a report.\n",
      "China's net users number 100m but this represents less than 8% of the\n",
      "country's 1.3 billion people.  Market analysts Panlogic predicts that\n",
      "net users in China will exceed the 137 million US users of the net by\n",
      "2008. The report says that the country's culture will mean that\n",
      "Chinese people will use the net for very different ends than in many\n",
      "other nations.\n",
      "\n",
      "Already net use in China has a very different\n",
      "character than in many Western nations, said William Makower, chief\n",
      "executive of Panlogic.  In many Western nations desktop computers that\n",
      "can access the net are hard to escape at work.  By contrast in China\n",
      "workplace machines are relatively rare.  This, combined with the\n",
      "relatively high cost of PCs in China and the time it takes to get\n",
      "phone lines installed, helps to explains the huge number of net cafes\n",
      "in China.  Only 36% of Chinese homes have telephones according to\n",
      "reports.  \"Net usage tends to happen in the evening,\" said Mr Makower,\n",
      "\"they get access only when they go home and go off to the internet\n",
      "caf&#233;.\" \"Its fundamentally different usage to what we have here,\"\n",
      "he said.\n",
      "\n",
      "Net use in China was still very much an urban phenomenon\n",
      "with most users living on the country's eastern seaboard or in its\n",
      "three biggest cities.  The net is key to helping Chinese people keep\n",
      "in touch with friends, said Mr Makower.  Many people use it in\n",
      "preference to the phone or arrange to meet up with friends at net\n",
      "cafes.  What people can do on the net is also limited by aspects of\n",
      "Chinese life.  For instance, said Mr Makower, credit cards are rare in\n",
      "China partly because of fears people have about getting in to debt.\n",
      "\"The most popular way to pay is Cash-On-Delivery,\" he said, \"and\n",
      "that's quite a brake to the development of e-commerce.\"  The arrival\n",
      "of foreign banks in China, due in 2006, could mean greater use of\n",
      "credit cards but for the moment they are rare, said Mr Makower.  But\n",
      "if Chinese people are not spending cash online they are interested in\n",
      "the news they can get via the net and the view it gives them on\n",
      "Western ways of living.  \"A large part of the attraction of the\n",
      "internet is that it goes below the radar,\" he said.  \"Generally it's\n",
      "more difficult for the government to be able to control it.\"  \"Its\n",
      "real value is as an open window onto what's happening elsewhere in the\n",
      "world,\" he said.  Government restrictions on how much advertising can\n",
      "appear on television means that the net is a source of many commercial\n",
      "messages Chinese people would not see anywhere else.  Familiarity with\n",
      "the net also has a certain social cachet.  \"It's a sign of them having\n",
      "made it that they can use the internet and navigate around it,\" said\n",
      "Mr Makower.\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635343f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad7f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words(\"english\"), norm=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b81a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25x175 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 274 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(sentences)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c88c3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(len(sentences))\n",
    "for i in range(len(sentences)):\n",
    "    row = X[i, :]\n",
    "    scores[i] = row[row != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1c8853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07692308, 0.1       , 0.08333333, 0.07692308, 0.06666667,\n",
       "       0.1       , 0.16666667, 0.05555556, 0.16666667, 0.06666667,\n",
       "       0.25      , 0.06666667, 0.09090909, 0.1       , 0.14285714,\n",
       "       0.07692308, 0.1       , 0.05882353, 0.06666667, 0.14285714,\n",
       "       0.2       , 0.11111111, 0.05555556, 0.16666667, 0.11111111])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d001954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "147c4f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: \n",
      "0.25: \"Its fundamentally different usage to what we have here,\" he\n",
      "said.\n",
      "0.20: \"Generally it's more difficult for the government to be able to\n",
      "control it.\"\n",
      "0.17: By contrast in China workplace machines are relatively rare.\n",
      "0.17: Only 36% of Chinese homes have telephones according to reports.\n",
      "0.17: Familiarity with the net also has a certain social cachet.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Summary: \")\n",
    "for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f: %s\" % (scores[i], sentences[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "787b09ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"China 'to overtake US net use'\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\", 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee2a1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    X = vectorizer.fit_transform(sents)\n",
    "    scores = np.zeros(len(sents))\n",
    "    for i in range(len(sents)):\n",
    "        row = X[i, :]\n",
    "        scores[i] = row[row != 0].mean()\n",
    "    sort_idx = np.argsort(-scores)\n",
    "    print(\"Generated Summary: \")\n",
    "    for i in sort_idx[:5]:\n",
    "        print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1613140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U2 to play at Grammy awards show\n",
      "Generated Summary: \n",
      "0.33: It will be held at the Staples Center.\n",
      "0.10: This year the Grammys have been dominated by rap star Kanye\n",
      "West, who is in contention for 10 awards.\n",
      "0.10: US comedian Ellen Degeneres and singer Christine Milian will\n",
      "present awards at the event.\n",
      "0.09: U2 are nominated twice for their recent single Vertigo,\n",
      "including a nomination for best rock song.\n",
      "0.08: Last week Grammy producers announced the show will be hosted by\n",
      "rap star and Chicago actress Queen Latifah.\n"
     ]
    }
   ],
   "source": [
    "doc = df[df.labels == \"entertainment\"][\"text\"].sample(random_state=1234)\n",
    "print(doc.iloc[0].split(\"\\n\", 1)[0])\n",
    "summarize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e4232",
   "metadata": {},
   "source": [
    "# Text Summarization Using TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89383b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bbc_text_cls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7200b952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72f22ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f289782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U2 to play at Grammy awards show\n",
      "\n",
      "Irish rock band U2 are to play live\n",
      "at the Grammy Awards presentation in the US next month, organisers\n",
      "have said.\n",
      "\n",
      "Other acts to play include soul singer Alicia Keys,\n",
      "country singer Tim McGraw and punk band Green Day at the event on 13\n",
      "February in Los Angeles.  U2 are nominated twice for their recent\n",
      "single Vertigo, including a nomination for best rock song.  This year\n",
      "the Grammys have been dominated by rap star Kanye West, who is in\n",
      "contention for 10 awards.  US comedian Ellen Degeneres and singer\n",
      "Christine Milian will present awards at the event.  Last week Grammy\n",
      "producers announced the show will be hosted by rap star and Chicago\n",
      "actress Queen Latifah.  It will be held at the Staples Center.  U2 had\n",
      "number one success in the album charts on both sides of the Atlantic\n",
      "in November when their latest studio album, How to Dismantle an Atomic\n",
      "Bomb, topped the US and UK charts.  The band, who are also dominated\n",
      "for best international album at this year's Brit Awards, are to\n",
      "undertake a major world tour this year, their first for four years.\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cfa15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5661d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words(\"english\"), norm=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef364c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9x93 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(sentences)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7dd1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cabf091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e907d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "S /= S.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6179e779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fb93692",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.ones_like(S) / len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11140fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4afc3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 0.15\n",
    "A = U * factor + S * (1 - factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05344d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "424f808f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.42269926, 0.48822834, 0.52764223, 0.85      ,\n",
       "       0.63054941, 0.67533336, 0.75015993, 0.72869529])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63a0d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36815542, 0.31882339, 0.31228841, 0.34754234, 0.33736123,\n",
       "       0.31007514, 0.33276299, 0.31397953, 0.35387845])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvecs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b46715ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36815542, 0.31882339, 0.31228841, 0.34754234, 0.33736123,\n",
       "       0.31007514, 0.33276299, 0.31397953, 0.35387845])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvecs[:, 0].dot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "579e19fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12292881, 0.10645662, 0.10427455, 0.11604601, 0.11264648,\n",
       "       0.10353553, 0.11111111, 0.10483923, 0.11816166])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_eig = eigvecs[:, 0] / eigvecs[:, 0].sum() \n",
    "norm_eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34f51abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 39\n"
     ]
    }
   ],
   "source": [
    "limiting_dist = np.ones(len(S)) / len(S)\n",
    "threshold = 1e-8\n",
    "delta = float(\"inf\")\n",
    "iters = 0\n",
    "while delta > threshold:\n",
    "    iters += 1\n",
    "    p = limiting_dist.dot(A)\n",
    "    delta = np.abs(limiting_dist - p).sum()\n",
    "    limiting_dist = p\n",
    "print(f\"Number of iterations: {iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0fdb9c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12292881, 0.10645661, 0.10427456, 0.11604601, 0.11264648,\n",
       "       0.10353553, 0.11111111, 0.10483923, 0.11816166])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "956e4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000036"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1da735e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.568320563167692e-08"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(norm_eig - limiting_dist).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f2293f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ebb953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "756562ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: \n",
      "0.12: \n",
      "Irish rock band U2 are to play live at the Grammy Awards\n",
      "presentation in the US next month, organisers have said.\n",
      "0.12: The band, who are also dominated for best international album at\n",
      "this year's Brit Awards, are to undertake a major world tour this\n",
      "year, their first for four years.\n",
      "0.12: This year the Grammys have been dominated by rap star Kanye\n",
      "West, who is in contention for 10 awards.\n",
      "0.11: US comedian Ellen Degeneres and singer Christine Milian will\n",
      "present awards at the event.\n",
      "0.11: It will be held at the Staples Center.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Summary: \")\n",
    "for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f: %s\" % (scores[i], sentences[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a345fb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U2 to play at Grammy awards show'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\", 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "964f82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, factor=0.15):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords.words(\"english\"), norm=\"l1\")\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "    S = cosine_similarity(X)\n",
    "    S /= S.sum(axis=1, keepdims=True)\n",
    "    S = np.ones_like(S) / len(S) * factor + (1 - factor) * S\n",
    "    eigvals, eigvecs = np.linalg.eig(S)\n",
    "    idx = 0\n",
    "    for i in range(len(eigvals)):\n",
    "        if eigvals[i] == 1:\n",
    "            idx = i\n",
    "            break\n",
    "    norm_eig = eigvecs[:, idx] / eigvecs[:, idx].sum()\n",
    "    scores = norm_eig\n",
    "    sort_idx = np.argsort(norm_eig)\n",
    "    print(\"Generated Summary: \")\n",
    "    for j in sort_idx[:5]:\n",
    "        print(wrap(\"%.2f: %s\" % (scores[j], sentences[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9013ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Evil twin' fear for wireless net\n",
      "Generated Summary: \n",
      "0.04: In the vast majority of cases, base stations straight out of the\n",
      "box from the manufacturers are automatically set up with the least\n",
      "secure mode possible, said Dr Nobles.\n",
      "0.04: Cybercriminals who try to glean personal information using the\n",
      "scam, jam connections to a legitimate base station by sending a\n",
      "stronger signal near to the wireless client.\n",
      "0.04: \"Cybercriminals don't have to be that clever to carry out such\n",
      "an attack,\" said Dr Phil Nobles, a wireless net and cybercrime expert\n",
      "at Cranfield.\n",
      "0.04: Dr Nobles is due to speak about wireless cybercrime at the\n",
      "Science Museum's Dana Centre in London on Thursday.\n",
      "0.04: A wireless network that is not protected can provide a backdoor\n",
      "into a company's computer system.\n"
     ]
    }
   ],
   "source": [
    "doc = df[df.labels == \"tech\"][\"text\"].sample(random_state=765)\n",
    "print(doc.iloc[0].split(\"\\n\", 1)[0])\n",
    "summarize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb0554",
   "metadata": {},
   "source": [
    "# Text Summarization Using Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0c4b2854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Collecting docopt<0.7,>=0.6.1\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pycountry>=18.2.23\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting breadability>=0.1.20\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from sumy) (2.27.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from sumy) (3.7)\n",
      "Requirement already satisfied: chardet in c:\\users\\developer\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.8.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\developer\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\developer\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\developer\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\developer\\anaconda3\\lib\\site-packages (from pycountry>=18.2.23->sumy) (61.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\developer\\anaconda3\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.4)\n",
      "Building wheels for collected packages: breadability, pycountry\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21712 sha256=c0fada659e66b7cc37595f70e82a9f16eaa27350ec651e282db11d19ff8063fb\n",
      "  Stored in directory: c:\\users\\developer\\appdata\\local\\pip\\cache\\wheels\\ba\\9f\\70\\7795228568b81b57a8932755938da9fb1f291b0576752604aa\n",
      "  Building wheel for pycountry (PEP 517): started\n",
      "  Building wheel for pycountry (PEP 517): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681895 sha256=6844e77d1bb9ab406e480e1ffbd898a0427808b4089a07386b0ebc5441802125\n",
      "  Stored in directory: c:\\users\\developer\\appdata\\local\\pip\\cache\\wheels\\47\\15\\92\\e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
      "Successfully built breadability pycountry\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f39e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a44195d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = TextRankSummarizer()\n",
    "parser = PlaintextParser.from_string(doc.iloc[0].split(\"\\n\", 1)[1], Tokenizer(\"english\"))\n",
    "summary = summarizer(parser.document, sentences_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "543c52f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: \"Users need to be wary of using their wi-fi enabled laptops or other portable devices in order to conduct financial transactions or anything that is of a sensitive or personal nature,\" said Professor Brian Collins, head of information systems at Cranfield University.>,\n",
       " <Sentence: BT Openzone, which operates a vast proportion of public hotspots in the UK, told the BBC News website that it made every effort to make its wi-fi secure.>,\n",
       " <Sentence: He said BT Openzone, as well as others, have sophisticated encryption from the start of the login process to the service at a hotspot.>,\n",
       " <Sentence: In the vast majority of cases, base stations straight out of the box from the manufacturers are automatically set up with the least secure mode possible, said Dr Nobles.>,\n",
       " <Sentence: Cybercriminals who try to glean personal information using the scam, jam connections to a legitimate base station by sending a stronger signal near to the wireless client.>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b990110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Users need to be wary of using their wi-fi enabled laptops or other\n",
      "portable devices in order to conduct financial transactions or\n",
      "anything that is of a sensitive or personal nature,\" said Professor\n",
      "Brian Collins, head of information systems at Cranfield University.\n",
      "BT Openzone, which operates a vast proportion of public hotspots in\n",
      "the UK, told the BBC News website that it made every effort to make\n",
      "its wi-fi secure.\n",
      "He said BT Openzone, as well as others, have sophisticated encryption\n",
      "from the start of the login process to the service at a hotspot.\n",
      "In the vast majority of cases, base stations straight out of the box\n",
      "from the manufacturers are automatically set up with the least secure\n",
      "mode possible, said Dr Nobles.\n",
      "Cybercriminals who try to glean personal information using the scam,\n",
      "jam connections to a legitimate base station by sending a stronger\n",
      "signal near to the wireless client.\n"
     ]
    }
   ],
   "source": [
    "for s in summary:\n",
    "    print(wrap(str(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0061dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest threat, nicknamed evil twins, pose as real hotspots but are\n",
      "actually unauthorised base stations, say Cranfield University experts.\n",
      "\"Users can also protect themselves by ensuring that their wi-fi device\n",
      "has its security measures activated,\" he added.\n",
      "\"Because wireless networks are based on radio signals they can be\n",
      "easily detected by unauthorised users tuning into the same frequency.\"\n",
      "Some companies have been reluctant to use them in large numbers\n",
      "because of fears about security.\n",
      "Dr Nobles is due to speak about wireless cybercrime at the Science\n",
      "Museum's Dana Centre in London on Thursday.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count=5)\n",
    "for s in summary:\n",
    "    print(wrap(str(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9b81e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\developer\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\developer\\anaconda3\\lib\\site-packages (from gensim) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
